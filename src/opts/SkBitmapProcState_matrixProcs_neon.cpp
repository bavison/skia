/* Copyright 2009 Motorola
 *
 * Use of this source code is governed by a BSD-style license that can be
 * found in the LICENSE file.
 */

#include "SkBitmapProcState.h"
#include "SkShader.h"
#include "SkUtilsArm.h"
#include "SkBitmapProcState_utils.h"

#include <arm_neon.h>

extern const SkBitmapProcState::MatrixProc ClampX_ClampY_Procs_neon[];
extern const SkBitmapProcState::MatrixProc RepeatX_RepeatY_Procs_neon[];

static void decal_nofilter_scale_neon(uint32_t dst[], SkFixed fx, SkFixed dx, int count);
static void decal_filter_scale_neon(uint32_t dst[], SkFixed fx, SkFixed dx, int count);

// TILEX_PROCF(fx, max)    SkClampMax((fx) >> 16, max)
static inline int16x8_t sbpsm_clamp_tile8(int32x4_t low, int32x4_t high, unsigned max) {
    int16x8_t res;

    // get the hi 16s of all those 32s
    res = vuzpq_s16(vreinterpretq_s16_s32(low), vreinterpretq_s16_s32(high)).val[1];

    // clamp
    res = vmaxq_s16(res, vdupq_n_s16(0));
    res = vminq_s16(res, vdupq_n_s16(max));

    return res;
}

// TILEX_PROCF(fx, max)    SkClampMax((fx) >> 16, max)
static inline int32x4_t sbpsm_clamp_tile4(int32x4_t f, unsigned max) {
    int32x4_t res;

    // get the hi 16s of all those 32s
    res = vshrq_n_s32(f, 16);

    // clamp
    res = vmaxq_s32(res, vdupq_n_s32(0));
    res = vminq_s32(res, vdupq_n_s32(max));

    return res;
}

// EXTRACT_LOW_BITS(fy, max)         (((fy) >> 12) & 0xF)
static inline int32x4_t sbpsm_clamp_tile4_low_bits(int32x4_t fx) {
    int32x4_t ret;

    ret = vshrq_n_s32(fx, 12);

    /* We don't need the mask below because the caller will
     * overwrite the non-masked bits
     */
    //ret = vandq_s32(ret, vdupq_n_s32(0xF));

    return ret;
}

// TILEX_PROCF(fx, max) (((fx)&0xFFFF)*((max)+1)>> 16)
static inline int16x8_t sbpsm_repeat_tile8(int32x4_t low, int32x4_t high, unsigned max) {
    uint16x8_t res;
    uint32x4_t tmpl, tmph;

    // get the lower 16 bits
    res = vuzpq_u16(vreinterpretq_u16_s32(low), vreinterpretq_u16_s32(high)).val[0];

    // bare multiplication, not SkFixedMul
    tmpl = vmull_u16(vget_low_u16(res), vdup_n_u16(max+1));
    tmph = vmull_u16(vget_high_u16(res), vdup_n_u16(max+1));

    // extraction of the 16 upper bits
    res = vuzpq_u16(vreinterpretq_u16_u32(tmpl), vreinterpretq_u16_u32(tmph)).val[1];

    return vreinterpretq_s16_u16(res);
}

// TILEX_PROCF(fx, max) (((fx)&0xFFFF)*((max)+1)>> 16)
static inline int32x4_t sbpsm_repeat_tile4(int32x4_t f, unsigned max) {
    uint16x4_t res;
    uint32x4_t tmp;

    // get the lower 16 bits
    res = vmovn_u32(vreinterpretq_u32_s32(f));

    // bare multiplication, not SkFixedMul
    tmp = vmull_u16(res, vdup_n_u16(max+1));

    // extraction of the 16 upper bits
    tmp = vshrq_n_u32(tmp, 16);

    return vreinterpretq_s32_u32(tmp);
}

// EXTRACT_LOW_BITS(fx, max)         ((((fx) & 0xFFFF) * ((max) + 1) >> 12) & 0xF)
static inline int32x4_t sbpsm_repeat_tile4_low_bits(int32x4_t fx, unsigned max) {
    uint16x4_t res;
    uint32x4_t tmp;
    int32x4_t ret;

    // get the lower 16 bits
    res = vmovn_u32(vreinterpretq_u32_s32(fx));

    // bare multiplication, not SkFixedMul
    tmp = vmull_u16(res, vdup_n_u16(max + 1));

    // shift and mask
    ret = vshrq_n_s32(vreinterpretq_s32_u32(tmp), 12);

    /* We don't need the mask below because the caller will
     * overwrite the non-masked bits
     */
    //ret = vandq_s32(ret, vdupq_n_s32(0xF));

    return ret;
}

#ifndef __ARM_64BIT_STATE

// The following functions have custom versions that override the SkBitmapProcState_matrix_neon.h templates

#define ClampX_ClampY_filter_scale_neon(s, xy, count, x, y) ClampX_ClampY_filter_scale_neon_autogenerated(s, xy, count, x, y)
static void (ClampX_ClampY_filter_scale_neon)(const SkBitmapProcState& s,
                                              uint32_t xy[], int count, int x, int y);

#endif

#define MAKENAME(suffix)                ClampX_ClampY ## suffix ## _neon
#define TILEX_PROCF(fx, max)            SkClampMax((fx) >> 16, max)
#define TILEY_PROCF(fy, max)            SkClampMax((fy) >> 16, max)
#define TILEX_PROCF_NEON8(l, h, max)    sbpsm_clamp_tile8(l, h, max)
#define TILEY_PROCF_NEON8(l, h, max)    sbpsm_clamp_tile8(l, h, max)
#define TILEX_PROCF_NEON4(fx, max)      sbpsm_clamp_tile4(fx, max)
#define TILEY_PROCF_NEON4(fy, max)      sbpsm_clamp_tile4(fy, max)
#define EXTRACT_LOW_BITS(v, max)        (((v) >> 12) & 0xF)
#define EXTRACT_LOW_BITS_NEON4(v, max)  sbpsm_clamp_tile4_low_bits(v)
#define CHECK_FOR_DECAL
#include "SkBitmapProcState_matrix_neon.h"

#define MAKENAME(suffix)                RepeatX_RepeatY ## suffix ## _neon
#define TILEX_PROCF(fx, max)            SK_USHIFT16(((fx) & 0xFFFF) * ((max) + 1))
#define TILEY_PROCF(fy, max)            SK_USHIFT16(((fy) & 0xFFFF) * ((max) + 1))
#define TILEX_PROCF_NEON8(l, h, max)    sbpsm_repeat_tile8(l, h, max)
#define TILEY_PROCF_NEON8(l, h, max)    sbpsm_repeat_tile8(l, h, max)
#define TILEX_PROCF_NEON4(fx, max)      sbpsm_repeat_tile4(fx, max)
#define TILEY_PROCF_NEON4(fy, max)      sbpsm_repeat_tile4(fy, max)
#define EXTRACT_LOW_BITS(v, max)        ((((v) & 0xFFFF) * ((max) + 1) >> 12) & 0xF)
#define EXTRACT_LOW_BITS_NEON4(v, max)  sbpsm_repeat_tile4_low_bits(v, max)
#include "SkBitmapProcState_matrix_neon.h"



void decal_nofilter_scale_neon(uint32_t dst[], SkFixed fx, SkFixed dx, int count) {
    if (count >= 8) {
        // SkFixed is 16.16 fixed point
        SkFixed dx8 = dx * 8;
        int32x4_t vdx8 = vdupq_n_s32(dx8);

        // setup lbase and hbase
        int32x4_t lbase, hbase;
        lbase = vdupq_n_s32(fx);
        lbase = vsetq_lane_s32(fx + dx, lbase, 1);
        lbase = vsetq_lane_s32(fx + dx + dx, lbase, 2);
        lbase = vsetq_lane_s32(fx + dx + dx + dx, lbase, 3);
        hbase = lbase + vdupq_n_s32(4 * dx);

        do {
            // store the upper 16 bits
            vst1q_u32(dst, vreinterpretq_u32_s16(
                vuzpq_s16(vreinterpretq_s16_s32(lbase), vreinterpretq_s16_s32(hbase)).val[1]
            ));

            // on to the next group of 8
            lbase += vdx8;
            hbase += vdx8;
            dst += 4; // we did 8 elements but the result is twice smaller
            count -= 8;
            fx += dx8;
        } while (count >= 8);
    }

    uint16_t* xx = (uint16_t*)dst;
    for (int i = count; i > 0; --i) {
        *xx++ = SkToU16(fx >> 16); fx += dx;
    }
}

void decal_filter_scale_neon(uint32_t dst[], SkFixed fx, SkFixed dx, int count) {
#ifndef __ARM_64BIT_STATE
    SkASSERT(((fx + (count-1) * dx) >> (16 + 14)) == 0);
    fx = (fx << 2) + 1;
    dx <<= 2;
    while (((uintptr_t) dst & 0xf) && --count >= 0) {
        *dst++ = (fx & 0xffffc001) + (fx >> 18);
        fx += dx;
    }
    if ((count -= 4) >= 0) {
        uint32_t tmp;
        __asm__ (
                "adr         %[tmp], 1f                  \n\t"
                "vmvn.i32    q10, #0x3fff                \n\t"
                "vld1.32     {q11}, [%[tmp]]             \n\t"
                "vdup.32     q8, %[fx]                   \n\t"
                "vdup.32     q9, %[dx]                   \n\t"
                "vsra.u32    q10, #31                    \n\t"
                "vmla.u32    q8, q9, q11                 \n\t"
                "vshl.u32    q9, #2                      \n\t"
                "b           2f                          \n\t"
                "1:                                      \n\t"
                ".long       0                           \n\t"
                ".long       1                           \n\t"
                ".long       2                           \n\t"
                ".long       3                           \n\t"
                "2:                                      \n\t"
                "vand        q11, q8, q10                \n\t"
                "vshr.u32    q12, q8, #18                \n\t"
                "vadd.i32    q11, q12                    \n\t"
                "vadd.i32    q8, q9                      \n\t"
                "subs        %[count], #4                \n\t"
                "vst1.32     {q11}, [%[dst]:128]!        \n\t"
                "bpl         2b                          \n\t"
                "vmov.32     %[fx], d16[0]               \n\t"
        : // Outputs
                [count]"+l"(count),
                  [dst]"+r"(dst),
                   [fx]"+r"(fx),
                  [tmp]"=&r"(tmp)
        : // Inputs
                [dx]"r"(dx)
        : // Clobbers
                "cc", "memory"
        );
    }
    if ((count += 4-1) >= 0) {
        do {
            *dst++ = (fx & 0xffffc001) + (fx >> 18);
            fx += dx;
        } while (--count >= 0);
    }
#else // !defined(__ARM_64BIT_STATE)
    if (count >= 8) {
        SkFixed dx8 = dx * 8;
        int32x4_t vdx8 = vdupq_n_s32(dx8);

        int32x4_t wide_fx, wide_fx2;
        wide_fx = vdupq_n_s32(fx);
        wide_fx = vsetq_lane_s32(fx + dx, wide_fx, 1);
        wide_fx = vsetq_lane_s32(fx + dx + dx, wide_fx, 2);
        wide_fx = vsetq_lane_s32(fx + dx + dx + dx, wide_fx, 3);

        wide_fx2 = vaddq_s32(wide_fx, vdupq_n_s32(4 * dx));

        while (count >= 8) {
            int32x4_t wide_out;
            int32x4_t wide_out2;

            wide_out = vshlq_n_s32(vshrq_n_s32(wide_fx, 12), 14);
            wide_out = wide_out | (vshrq_n_s32(wide_fx,16) + vdupq_n_s32(1));

            wide_out2 = vshlq_n_s32(vshrq_n_s32(wide_fx2, 12), 14);
            wide_out2 = wide_out2 | (vshrq_n_s32(wide_fx2,16) + vdupq_n_s32(1));

            vst1q_u32(dst, vreinterpretq_u32_s32(wide_out));
            vst1q_u32(dst+4, vreinterpretq_u32_s32(wide_out2));

            dst += 8;
            fx += dx8;
            wide_fx += vdx8;
            wide_fx2 += vdx8;
            count -= 8;
        }
    }

    if (count & 1)
    {
        SkASSERT((fx >> (16 + 14)) == 0);
        *dst++ = (fx >> 12 << 14) | ((fx >> 16) + 1);
        fx += dx;
    }
    while ((count -= 2) >= 0)
    {
        SkASSERT((fx >> (16 + 14)) == 0);
        *dst++ = (fx >> 12 << 14) | ((fx >> 16) + 1);
        fx += dx;

        *dst++ = (fx >> 12 << 14) | ((fx >> 16) + 1);
        fx += dx;
    }
#endif
}

#ifndef __ARM_64BIT_STATE

static void (ClampX_ClampY_filter_scale_neon)(const SkBitmapProcState& s,
                                              uint32_t xy[], int count, int x, int y) {
    (void) ClampX_ClampY_filter_scale_neon_autogenerated; // Tell compiler we really don't want to use old version
    SkASSERT((s.fInvType & ~(SkMatrix::kTranslate_Mask |
                             SkMatrix::kScale_Mask)) == 0);
    SkASSERT(s.fInvKy == 0);

    const unsigned maxX = s.fPixmap.width() - 1;
    const SkFixed one = s.fFilterOneX;
    const SkFractionalInt dx = s.fInvSxFractionalInt;
    SkFractionalInt fx;

    {
        const SkBitmapProcStateAutoMapper mapper(s, x, y);
        const SkFixed fy = mapper.fixedY();
        const unsigned maxY = s.fPixmap.height() - 1;
        // compute our two Y values up front
        *xy++ = ClampX_ClampY_pack_filter_y_neon(fy, maxY, s.fFilterOneY );
        // now initialize fx
        fx = mapper.fractionalIntX();
    }

#ifdef CHECK_FOR_DECAL
    // test if we don't need to apply the tile proc
    const SkFixed fixedFx = ((SkFixed)((fx) >> 16));
    const SkFixed fixedDx = ((SkFixed)((dx) >> 16));
    if (can_truncate_to_fixed_for_decal(fixedFx, fixedDx, count, maxX)) {
        decal_filter_scale_neon(xy, fixedFx, fixedDx, count);
        return;
    }
#endif

    if (one == SK_Fixed1) {
        SkASSERT(maxX < (1<<14)-1);
        if (dx >= 0) {
            --count;
            while (count >= 0 && fx < 0) {
                *xy++ = 0;
                fx += dx;
                --count;
            }
            while (count >= 0 && ((uintptr_t) xy & 0xf) && fx < ((SkFractionalInt) maxX << 32)) {
                *xy++ = ((uint32_t)(fx >> 14) & 0xffffc000) + (uint32_t)(fx >> 32) + 1;
                fx += dx;
                --count;
            }
            if ((count -= 8-1) >= 0 && fx + 7*dx < ((SkFractionalInt) maxX << 32)) {
                SkFractionalInt rem = (((SkFractionalInt) maxX << 32) - 7*dx - fx - 1) / 8;
                int32_t rem_hi = rem >> 32;
                uint32_t rem_lo = (uint32_t) rem;
                int32_t fx_hi = fx >> 32;
                uint32_t fx_lo = (uint32_t) fx;
                __asm__ (
                        "vmov        d16, %[fx_lo], %[fx_hi]     \n\t"
                        "vmov        d24, %[dx_lo], %[dx_hi]     \n\t"
                        "vadd.i64    d17, d16, d24               \n\t"
                        "vmov        d25, %[dx_lo], %[dx_hi]     \n\t"
                        "vmvn.i32    q13, #0x3fff                \n\t"
                        "vadd.i64    d18, d17, d24               \n\t"
                        "vmov.i32    q14, #1                     \n\t"
                        "vadd.i64    d19, d18, d24               \n\t"
                        "vshl.i64    q12, #2                     \n\t"
                        "b           2f                          \n\t"
                        "1:                                      \n\t"
                        "vadd.i64    q8, q10, q12                \n\t"
                        "vadd.i64    q9, q11, q12                \n\t"
                        "2:                                      \n\t"
                        "vadd.i64    q10, q8, q12                \n\t"
                        "vadd.i64    q11, q9, q12                \n\t"
                        "vshrn.i64   d16, q8, #14                \n\t"
                        "vshrn.i64   d17, q9, #14                \n\t"
                        "vand        q8, q13                     \n\t"
                        "vorr        q8, q14                     \n\t"
                        "vshrn.i64   d18, q10, #14               \n\t"
                        "vshrn.i64   d19, q11, #14               \n\t"
                        "vand        q9, q13                     \n\t"
                        "subs        %[rem_lo], %[dx_lo]         \n\t"
                        "vorr        q9, q14                     \n\t"
                        "sbcs        %[rem_hi], %[dx_hi]         \n\t"
                        "vsra.u32    q8, #18                     \n\t"
                        "subs        %[count], #8                \n\t"
                        "vsra.u32    q9, #18                     \n\t"
                        "it          pl                          \n\t"
                        "teqpl       %[rem_hi], #0               \n\t"
                        "vst1.32     {q8-q9}, [%[dst]:128]!      \n\t"
                        "bpl         1b                          \n\t"
                        "vadd.i64    d16, d20, d24               \n\t"
                        "vmov        %[fx_lo], %[fx_hi], d16     \n\t"
                : // Outputs
                         [count]"+l"(count),
                           [dst]"+r"(xy),
                        [rem_hi]"+l"(rem_hi),
                        [rem_lo]"+l"(rem_lo),
                         [fx_hi]"+r"(fx_hi),
                         [fx_lo]"+r"(fx_lo)
                : // Inputs
                        [dx_hi]"l"((int32_t) (dx >> 32)),
                        [dx_lo]"l"((uint32_t) dx)
                : // Clobbers
                        "cc", "memory"
                );
                fx = ((SkFractionalInt) fx_hi << 32) | fx_lo;
            }
            count += 8-1;
            while (count >= 0 && fx < ((SkFractionalInt) maxX << 32)) {
                *xy++ = ((uint32_t)(fx >> 14) & 0xffffc000) + (uint32_t)(fx >> 32) + 1;
                fx += dx;
                --count;
            }
            while (count >= 0) {
                *xy++ = (maxX << 18) + maxX;
                --count;
            }
        } else {
            // Reflection case. Don't bother to optimize this as much -
            // not even sure if it's used!
            while (count >= 1 && fx >= ((SkFractionalInt) maxX << 32)) {
                *xy++ = (maxX << 18) + maxX;
                fx += dx;
                --count;
            }
            while (count >= 1 && fx >= 0) {
                *xy++ = ((uint32_t)(fx >> 14) & 0xffffc000) + (uint32_t)(fx >> 32) + 1;
                fx += dx;
                --count;
            }
            while (count >= 1) {
                *xy++ = 0;
                --count;
            }
        }
    }
    else
    {
        // Drop back to old code for other values of 'one'
        if (count >= 4) {
            int32x4_t wide_fx;

            wide_fx = vdupq_n_s32(SkFractionalIntToFixed(fx));
            wide_fx = vsetq_lane_s32(SkFractionalIntToFixed(fx+dx), wide_fx, 1);
            wide_fx = vsetq_lane_s32(SkFractionalIntToFixed(fx+dx+dx), wide_fx, 2);
            wide_fx = vsetq_lane_s32(SkFractionalIntToFixed(fx+dx+dx+dx), wide_fx, 3);

            while (count >= 4) {
                int32x4_t res;

                res = ClampX_ClampY_pack_filter_x4_neon(wide_fx, maxX, one);

                vst1q_u32(xy, vreinterpretq_u32_s32(res));

                wide_fx += vdupq_n_s32(SkFractionalIntToFixed(dx+dx+dx+dx));
                fx += dx+dx+dx+dx;
                xy += 4;
                count -= 4;
            }
        }

        while (--count >= 0) {
            *xy++ = ClampX_ClampY_pack_filter_x_neon(SkFractionalIntToFixed(fx), maxX, one);
            fx += dx;
        }
    }
}

#endif
